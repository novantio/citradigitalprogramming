{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33faadf7-aa3e-46e8-8294-738fd176cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature.texture import graycomatrix, graycoprops\n",
    "from skimage.feature import local_binary_pattern,hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff9a67e5-763f-4a91-930b-d9471b4798cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import  local_binary_pattern,graycomatrix, graycoprops\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ===============================\n",
    "# Parameter LBP\n",
    "# ===============================\n",
    "radius = 3\n",
    "n_points = 8 * radius\n",
    "\n",
    "# ===============================\n",
    "# Fungsi ekstraksi fitur\n",
    "# ===============================\n",
    "def extract_features(image):\n",
    "    # Pastikan gambar grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # --- LBP ---\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points+3), range=(0, n_points+2))\n",
    "    lbp_hist = lbp_hist.astype('float')\n",
    "    lbp_hist /= (lbp_hist.sum() + 1e-6)  # Normalisasi\n",
    "    \n",
    "    # --- GLCM ---\n",
    "    glcm = graycomatrix(gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    contrast = graycoprops(glcm, 'contrast')[0,0]\n",
    "    dissimilarity = graycoprops(glcm, 'dissimilarity')[0,0]\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity')[0,0]\n",
    "    energy = graycoprops(glcm, 'energy')[0,0]\n",
    "    correlation = graycoprops(glcm, 'correlation')[0,0]\n",
    "    \n",
    "    glcm_features = np.array([contrast, dissimilarity, homogeneity, energy, correlation])\n",
    "\n",
    "    # --- GLCM Multi Angle---\n",
    "    #angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    #glcm = graycomatrix(gray, distances=[1], angles=angles, levels=256, symmetric=True, normed=True)\n",
    "\n",
    "    #contrast     = np.mean(graycoprops(glcm, 'contrast')[0, :])\n",
    "    #dissimilarity= np.mean(graycoprops(glcm, 'dissimilarity')[0, :])\n",
    "    #homogeneity  = np.mean(graycoprops(glcm, 'homogeneity')[0, :])\n",
    "    #energy       = np.mean(graycoprops(glcm, 'energy')[0, :])\n",
    "    #correlation  = np.mean(graycoprops(glcm, 'correlation')[0, :])\n",
    "\n",
    "    #glcm_features = np.array([contrast, dissimilarity, homogeneity, energy, correlation])\n",
    "\n",
    "    \n",
    "\n",
    "    # ======================\n",
    "    # HOG\n",
    "    # ======================\n",
    "    #hog_feat = hog(\n",
    "    #    gray,\n",
    "    #    orientations=8,\n",
    "    #    pixels_per_cell=(16, 16),\n",
    "    #    cells_per_block=(2, 2),\n",
    "    #    block_norm='L2-Hys',\n",
    "    #    feature_vector=True\n",
    "    #)\n",
    "    \n",
    "    # Gabungkan fitur LBP + GLCM + HOG\n",
    "    #features = np.hstack([lbp_hist, glcm_features,hog_feat])\n",
    "    #features = np.hstack([ glcm_features,hog_feat])\n",
    "    features = np.hstack([ lbp_hist,glcm_features])\n",
    "    return features\n",
    "\n",
    "# ===============================\n",
    "# Load dataset\n",
    "# ===============================\n",
    "def load_dataset(folder_tb, folder_normal):\n",
    "    X, y = [], []\n",
    "    for img_name in os.listdir(folder_tb):\n",
    "        img_path = os.path.join(folder_tb, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            X.append(extract_features(img))\n",
    "            y.append(1)  # label TB\n",
    "    \n",
    "    for img_name in os.listdir(folder_normal):\n",
    "        img_path = os.path.join(folder_normal, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            X.append(extract_features(img))\n",
    "            y.append(0)  # label normal\n",
    "            \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# ===============================\n",
    "# Tentukan folder               #\n",
    "# ===============================\n",
    "folder_tb = r'D:\\project\\python\\2025\\tbcdetect\\dataset2\\TB_Chest_Radiography_Database\\Train\\tb'\n",
    "folder_normal = r'D:\\project\\python\\2025\\tbcdetect\\dataset2\\TB_Chest_Radiography_Database\\Train\\normal'\n",
    "\n",
    "X, y = load_dataset(folder_tb, folder_normal)\n",
    "\n",
    "# ===============================\n",
    "# Split dataset\n",
    "# ===============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025e2fc8-0ebf-4d02-a832-f6604ea87808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9916666666666667\n",
      "SVM Accuracy: 0.9892857142857143\n",
      "KNN Accuracy: 0.9845238095238096\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# Random Forest\n",
    "# ===============================\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "# ===============================\n",
    "# SVM dengan normalisasi\n",
    "# ===============================\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svm = SVC(kernel='rbf', C=1.0 , random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "\n",
    "# ===============================\n",
    "# KNN\n",
    "# ===============================\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "656343ce-19a9-4503-be60-dfacb7e17cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RANDOM FOREST ===\n",
      "Accuracy: 0.9916666666666667\n",
      "\n",
      "Confusion Matrix:\n",
      " [[699   1]\n",
      " [  6 134]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       700\n",
      "           1       0.99      0.96      0.97       140\n",
      "\n",
      "    accuracy                           0.99       840\n",
      "   macro avg       0.99      0.98      0.98       840\n",
      "weighted avg       0.99      0.99      0.99       840\n",
      "\n",
      "\n",
      "=== SVM (Normalized) ===\n",
      "Accuracy: 0.9892857142857143\n",
      "\n",
      "Confusion Matrix:\n",
      " [[700   0]\n",
      " [  9 131]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       700\n",
      "           1       1.00      0.94      0.97       140\n",
      "\n",
      "    accuracy                           0.99       840\n",
      "   macro avg       0.99      0.97      0.98       840\n",
      "weighted avg       0.99      0.99      0.99       840\n",
      "\n",
      "\n",
      "=== KNN ===\n",
      "Accuracy: 0.9845238095238096\n",
      "\n",
      "Confusion Matrix:\n",
      " [[697   3]\n",
      " [ 10 130]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       700\n",
      "           1       0.98      0.93      0.95       140\n",
      "\n",
      "    accuracy                           0.98       840\n",
      "   macro avg       0.98      0.96      0.97       840\n",
      "weighted avg       0.98      0.98      0.98       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 1. RANDOM FOREST\n",
    "# ===============================\n",
    "print(\"\\n=== RANDOM FOREST ===\")\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, rf_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, rf_pred))\n",
    "\n",
    "# ===============================\n",
    "# 2. SVM (dengan normalisasi)\n",
    "# ===============================\n",
    "print(\"\\n=== SVM (Normalized) ===\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svm = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "svm_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, svm_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, svm_pred))\n",
    "\n",
    "# ===============================\n",
    "# 3. KNN (butuh normalisasi juga)\n",
    "# ===============================\n",
    "print(\"\\n=== KNN ===\")\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "knn_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, knn_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, knn_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a03d0d-dd1e-4ba4-ac8b-bafcebeeeed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset...\n",
      "[INFO] Dataset loaded: (662, 319) samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Extra features\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops, hog\n",
    "\n",
    "# ML tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# ===============================\n",
    "# Parameter LBP\n",
    "# ===============================\n",
    "radius = 3\n",
    "n_points = 8 * radius\n",
    "\n",
    "# ===============================\n",
    "# Fungsi ekstraksi fitur\n",
    "# ===============================\n",
    "def extract_features(image):\n",
    "    # Resize agar HOG stabil\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # ======================\n",
    "    # LBP\n",
    "    # ======================\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    lbp_hist, _ = np.histogram(\n",
    "        lbp.ravel(),\n",
    "        bins=np.arange(0, n_points + 3),\n",
    "        range=(0, n_points + 2)\n",
    "    )\n",
    "    lbp_hist = lbp_hist / (lbp_hist.sum() + 1e-6)\n",
    "\n",
    "    # ======================\n",
    "    # GLCM\n",
    "    # ======================\n",
    "    glcm = graycomatrix(\n",
    "        gray,\n",
    "        distances=[1],\n",
    "        angles=[0],        # 0 derajat\n",
    "        levels=256,\n",
    "        symmetric=True,\n",
    "        normed=True\n",
    "    )\n",
    "\n",
    "    glcm_features = [\n",
    "        graycoprops(glcm, 'contrast')[0,0],\n",
    "        graycoprops(glcm, 'dissimilarity')[0,0],\n",
    "        graycoprops(glcm, 'homogeneity')[0,0],\n",
    "        graycoprops(glcm, 'energy')[0,0],\n",
    "        graycoprops(glcm, 'correlation')[0,0]\n",
    "    ]\n",
    "\n",
    "    # ======================\n",
    "    # HOG\n",
    "    # ======================\n",
    "    hog_feat = hog(\n",
    "        gray,\n",
    "        orientations=8,\n",
    "        pixels_per_cell=(32, 32),\n",
    "        cells_per_block=(2, 2),\n",
    "        block_norm='L2-Hys',\n",
    "        feature_vector=True\n",
    "    )\n",
    "\n",
    "    # ======================\n",
    "    # Gabungkan semua fitur\n",
    "    # ======================\n",
    "    features = np.hstack([lbp_hist, glcm_features, hog_feat])\n",
    "    return features\n",
    "\n",
    "# ===============================\n",
    "# Load dataset\n",
    "# ===============================\n",
    "def load_dataset(folder_tb, folder_normal):\n",
    "    X, y = [], []\n",
    "\n",
    "    for img_name in os.listdir(folder_tb):\n",
    "        img_path = os.path.join(folder_tb, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            X.append(extract_features(img))\n",
    "            y.append(1)  # TB\n",
    "\n",
    "    for img_name in os.listdir(folder_normal):\n",
    "        img_path = os.path.join(folder_normal, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            X.append(extract_features(img))\n",
    "            y.append(0)  # Normal\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# ===============================\n",
    "# Tentukan folder dataset\n",
    "# ===============================\n",
    "folder_tb = r\"D:\\project\\python\\2025\\tbcdetect\\_data_shenzhen\\train\\tb\"\n",
    "folder_normal = r\"D:\\project\\python\\2025\\tbcdetect\\_data_shenzhen\\train\\normal\"\n",
    "\n",
    "print(\"[INFO] Loading dataset...\")\n",
    "X, y = load_dataset(folder_tb, folder_normal)\n",
    "print(\"[INFO] Dataset loaded:\", X.shape, \"samples\")\n",
    "\n",
    "# ===============================\n",
    "# Split train/test\n",
    "# ===============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633650e0-1471-45eb-a21c-1d2fcfd04dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# StandardScaler\n",
    "# ===============================\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "# ===============================\n",
    "# PCA â†’ Kurangi fitur jadi 100\n",
    "# ===============================\n",
    "print(\"[INFO] Applying PCA...\")\n",
    "pca = PCA(n_components=100)\n",
    "X_train_p = pca.fit_transform(X_train_s)\n",
    "X_test_p = pca.transform(X_test_s)\n",
    "\n",
    "# ===============================\n",
    "# SVM\n",
    "# ===============================\n",
    "print(\"[INFO] Training SVM...\")\n",
    "svm = SVC(kernel='rbf', C=10, gamma='scale')\n",
    "svm.fit(X_train_p, y_train)\n",
    "\n",
    "# ===============================\n",
    "# Evaluasi\n",
    "# ===============================\n",
    "y_pred = svm.predict(X_test_p)\n",
    "\n",
    "print(\"\\n========== HASIL AKHIR ==========\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c8f2c7-a684-460c-a690-0fd97585eef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as tb_classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# ========================================================\n",
    "# SIMPAN MODEL KE PICKLE\n",
    "# ========================================================\n",
    "model_pack = {\n",
    "    \"model\": svm,\n",
    "    \"scaler\": scaler,\n",
    "    \"radius\": radius,\n",
    "    \"n_points\": n_points\n",
    "}\n",
    "\n",
    "with open(\"tb_classifier_svm.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_pack, f)\n",
    "\n",
    "print(\"Model saved as tb_classifier.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7b3c8f-663d-47ac-bef4-396bc9db75b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.12",
   "language": "python",
   "name": "py3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
